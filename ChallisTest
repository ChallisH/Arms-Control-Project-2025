### Example script for reading files with SpecUtils
### Created 02/11/2025
import warnings

import lmfit
import becquerel as bq
import SpecUtils
import math
import numpy as np
import scipy
import matplotlib.pyplot as plt
from scipy.stats import norm
from typing import Any

#help(specutils.utils.wcs_utils)

########## FROM Becquerels Example ###############

%matplotlib inline
plt.rcParams["figure.facecolor"] = "white"

%load_ext autoreload
%autoreload 2

np.random.seed(0)

warnings.filterwarnings("ignore")



##############

def load_spectra(path_to_spectra: str) -> SpecUtils.SpecFile():
    """
    Loads spectrum file automatically for a given file type.
    SpecUtils.ParserType.Auto will try to automatically determine
    the file extension, so verify you are loading a compatible file"""

    spec_file = SpecUtils.SpecFile()
    try:
        spec_file.loadFile(path_to_spectra, SpecUtils.ParserType.Auto)
        return spec_file

    except RuntimeError as e:
        raise Exception(f"Failed to decode file: {e}")

    return

def parse_title(spectrum_title: str) -> dict[str, Any]:
    """
    Parses all the information in my (Tanner's) .pcf file titles
    and loads it into a dictionary.

    A few notes:
        1. There is a bit of information here not useful for the
           arm control information barriers project but is here
           because of another project. You will not need things like
           nps, U235 content, etc.
        2. Pu239, Pu240, and other isotopics are weight fractions
           are represented as NEGATIVE NUMBERS and you might want to
           switch them back to positive.
        3. det_max_erg is in MeV, but its more common to use keV.
        4. PuRatio is just the ratio of Pu240/Pu239 and is positive
           already since, yknow, negative divided by a negative.
        5. NPS is a relic. Ignore, as it makes no sense in this context.
        6. Titles are unique to the person/software that generated the
           spectrum. If/when you use another detector or input a spectrum
           I did not provide, the title will be different and this function
           will not work.

    Args:
        spectrum_title: spectrum title as string

    Returns:
        Dictionary containing what the spectrum represents
    """

    try: # This is to ensure the code still works if given a file without Tanner's naming convention
        
        snm, U232, U235, U238, Pu239, Pu240, Pu241, PuRatio, age, snmir, snmor, \
        U_mass, Pu_mass, shd_mat, shdor, det_type, det_dist, det_bins, det_max_erg, \
        nps = spectrum_title.split("_")

        return {"snm":	snm, "U232": float(U232), "U235": float(U235), "U238": float(U238), "Pu239": float(Pu239),
            "Pu240": float(Pu240), "Pu241": float(Pu241), "PuRatio": float(PuRatio), "age": int(age),
            "snmir": float(snmir), "snmor": float(snmor), "U_mass": float(U_mass), "Pu_mass": float(Pu_mass),
            "shd_mat": shd_mat, "shdor": float(shdor), "det_type": det_type, "det_dist": float(det_dist),
            "det_bins": int(det_bins), "det_max_erg": float(det_max_erg), "nps": nps }
        
    except: # If the file title doesn't have Tanner's style, these will be the returned values, all numbers are 0's and all strings say 'N/A'
        
        return {"snm":	'N/A', "U232": 0, "U235": 0, "U238": 0, "Pu239": 0,
            "Pu240": 0, "Pu241": 0, "PuRatio": 0, "age": 0,
            "snmir": 0, "snmor": 0, "U_mass": 0, "Pu_mass": 0,
            "shd_mat": 'N/A', "shdor": 0, "det_type": 'N/A', "det_dist": 0,
            "det_bins": 0, "det_max_erg": 0, "nps": 'N/A' }

def ratioCalc(Amp239 , Amp240):

    '''
    Inputs: Intensity of Pu239 emissions at 645 keV and of 240 at 642 keV
    This will need an intensity from the Pu239 and 240 peaks to glean an isotopic ratio of the two

    NOTE: This is calculating an atomic ratio of the two based on the intensity of the 2 isotopes.
    The tricky bit is deconvoluting the spectrum into individual peaks for these emissions and using those peak
    areas along with their relative efficiency differences to find these intensities.

    All values pulled from Brookhaven: https://www.nndc.bnl.gov/nudat3/dec_searchi.jsp

    Pu239 has emission at 639.9 keV at 8.70E-6% intensity, possibly the middle peak
    '''
    t239 = 24110 # Half-life of Pu239 in years

    t240 = 6561 # Half-life of Pu240 in years
    
    lambda239 = np.log(2)/(t239 * 365 * 24 * 60 *60) #lambda from halflife of Pu239 in seconds 

    lambda240 = np.log(2)/(t240 * 365 * 24 * 60 *60) #lambda from halflife of Pu234 in seconds

    Bi_Pu240_642 = 1.248E-5 #Branching Intensity for Pu240 emission of 642.23 keV

    Bi_Pu239_645 = 1.52E-5 #Branching Intensity for Pu239 emission of 645.94 keV 

    return ((Amp239/(lambda239 * Bi_Pu239_645)) / ((Amp239/(lambda239 * Bi_Pu239_645) + (Amp240/(lambda240 * Bi_Pu240_642)))))

def ratioCalcAllPeaks(Amp239 , Amp240 , AmpDouble , AmpMiddle):

    '''
    Inputs: Intensity of Pu239 emissions at 637.7 , 637.8 , 639.9, and 645 keV and of Pu240 at 642 keV
    This will need an intensity from the Pu239 and 240 peaks to glean an isotopic ratio of the two

    NOTE: This is calculating an atomic ratio of the two based on the intensity of the 2 isotopes.
    The tricky bit is deconvoluting the spectrum into individual peaks for these emissions and using those peak
    areas along with their relative efficiency differences to find these intensities.

    All values pulled from Brookhaven: https://www.nndc.bnl.gov/nudat3/dec_searchi.jsp

    This tends to overshoot the amount of Pu239, so typically just use the ratioCalc() function for calculations
    '''
    t239 = 24110 # Half-life of Pu239 in years

    t240 = 6561 # Half-life of Pu240 in years
    
    lambda239 = np.log(2)/(t239 * 365 * 24 * 60 *60) #lambda from halflife of Pu239 in seconds 

    lambda240 = np.log(2)/(t240 * 365 * 24 * 60 *60) #lambda from halflife of Pu234 in seconds

    Bi_239_6377 = 2.56E-6 #Branching Intensity for Pu239 emission of 637.7 keV

    Bi_239_6378 = 2.56E-6 #Branching Intensity for Pu239 emission of 637.8 keV

    Bi_239_6399 = 8.70E-6 #Branching Intensity for Pu239 emission of 639.9 keV

    Bi_Pu240_642 = 1.248E-5 #Branching Intensity for Pu240 emission of 642.23 keV

    Bi_Pu239_645 = 1.52E-5 #Branching Intensity for Pu239 emission of 645.94 keV 

    return ((Amp239/(lambda239 * Bi_Pu239_645) + AmpDouble/(lambda239 * (Bi_239_6377 + Bi_239_6378)) + AmpMiddle/(lambda239 * Bi_239_6399)) / 
            ((Amp239/(lambda239 * Bi_Pu239_645) + AmpDouble/(lambda239 * (Bi_239_6377 + Bi_239_6378)) + AmpMiddle/(lambda239 * Bi_239_6399)
              + (Amp240/(lambda240 * Bi_Pu240_642)))))

def nearestPeak(targets , xEnergy , yCounts):

    '''
    value: Array of energies of peaks of interest (i.e. for Pu239 value = 645.97 keV)
    
    array: channels or energies of interest (filteredEnergy is my default)
    
    dps: CPS array without background, I linearly subtracted background from my OG CPS array
    and created CPSNoBkrnd as my default
        
    spread: Number of points before and after the peak that should be used for creating the 
            polynomial fit. My default is 2 because a lot of these peaks appear to have 2 points
            before and after the apex that are relatively unaffected by the other emissions

    Returns:

        Curve - Array of CPS or Counts to be plotted with the original spectrum

        Indices - The indices of the 
                    
    '''

    xVals = []

    yVals = []

    index = 0

    for i in targets:

        index = np.argmin((np.abs(xEnergy-i)))

        xVals.append(xEnergy[index])

        yVals.append(yCounts[index])

    return xVals , yVals
    

def peakVals(xEnergy , yCounts , focus=10):
    
    peakIdx = scipy.signal.find_peaks(yCounts , height = focus)[0]

    allPeakE = xEnergy[peakIdx]

    allPeakC = yCounts[peakIdx]

    return allPeakE , allPeakC

################## Bq TIME #########################

            
def multGaussSet(xEnergy , yCounts , yUnc , gaussPeakEnergy = np.array([637.75 , 639.99 , 642.23 , 645.94]) ,
                 tXVals = np.array([635.1 , 648.2])):

    '''
    Inputs: xEnergy - energy bins of interest
            yCounts - Counts for energy bins of interest
            yUnc - sqrt of yCounts (uncertainty in counts)
            gaussPeakEnergy - known gamma emissions of Pu239 and Pu240 in our cluster of interest
                * Pu239 emits a gamma at 637.7 keV and 637.8 keV, but the de-convolution cannot break these into 2 similarly sized peaks
                    therefore I am calling this one emission at 637.75
            troughTargets - border values around the peak cluster of interest
            
    Returns: gaussPeakEnergy - energies of the peaks of interest
            gaussPeakCounts - Counts for the peaks of interest
            tXVals - energies of the border values
            tYVals - counts of the border values

    NOTE: After using this function on some well defined spectra and fitting gaussians as intended,
            I am using the values of energy for those peaks on the other spectra to see if it will fit
            a similar gaussian cluster
    '''

    peakIndices = [np.where(np.isclose(xEnergy, e , rtol=2e-04 , atol=1e-08))[0][0] for e in gaussPeakEnergy]

    gaussPeakCounts = np.array(yCounts[peakIndices])

    troughIndices = [np.where(np.isclose(xEnergy, e , rtol=2e-04 , atol=1e-08))[0][0] for e in tXVals]

    tYVals = np.array(yCounts[troughIndices])

    width = (tXVals[1] - tXVals[0])/4

    

    model = (
        bq.fitting.GaussModel(prefix="gauss0_")
        + bq.fitting.GaussModel(prefix="gauss1_")
        + bq.fitting.GaussModel(prefix="gauss2_")
        + bq.fitting.GaussModel(prefix="gauss3_")
        + lmfit.models.LinearModel(prefix="line_")
    )
            
    params = {
        "gauss0_amp": gaussPeakCounts[0],
        "gauss0_mu": gaussPeakEnergy[0],
        "gauss0_sigma": width,
        "gauss1_amp": gaussPeakCounts[1],
        "gauss1_mu": gaussPeakEnergy[1],
        "gauss1_sigma": width,
        "gauss2_amp": gaussPeakCounts[2],
        "gauss2_mu": gaussPeakEnergy[2],
        "gauss2_sigma": width,
        "gauss3_amp": gaussPeakCounts[3],
        "gauss3_mu": gaussPeakEnergy[3],
        "gauss3_sigma": width,
        "line_slope": (tYVals[1]-tYVals[0])/(tXVals[1]-tXVals[0]),
        "line_intercept": tYVals[0] - ((tYVals[1]-tYVals[0])/(tXVals[1]-tXVals[0])) * tXVals[0],
    }
            
    fitter = bq.Fitter(
        model,
        x = xEnergy ,
        y = yCounts,
        y_unc = yUnc,
        roi=(tXVals[0] , tXVals[1]),
    )
    
    fitter.params["gauss0_mu"].set(value=gaussPeakEnergy[0])
    fitter.params["gauss1_mu"].set(value=gaussPeakEnergy[1])
    fitter.params["gauss2_mu"].set(value=gaussPeakEnergy[2])
    fitter.params["gauss3_mu"].set(value=gaussPeakEnergy[3])
    #fitter.fit(backend="lmfit") # Comment out the fitter.fit() and uncomment this to see if the residuals decrease with an exponential background fit
    #fitter.fit(backend="minuit-pml") #Also test this to see if it reduces error, last time it broke everything and made me tweak out
    fitter.fit() # The std's increase as counts increase, I think it is statistically a bad thing when there are obvious trends in error with data like this
    fitter.custom_plot(residual_type="sigma")
    #fitter.custom_plot() # Shows residuals as absolute difference between 
    plt.tight_layout()
    plt.show()

    result = fitter.result

    amp_double = result.params["gauss0_amp"].value
    amp_middle = result.params["gauss1_amp"].value
    amp_240 = result.params["gauss2_amp"].value
    amp_239 = result.params["gauss3_amp"].value
    

    fwhm240 = 2 * np.sqrt(2 * np.log(2)) * result.params["gauss2_sigma"].value
    fwhm239 = 2 * np.sqrt(2 * np.log(2)) * result.params["gauss3_sigma"].value

    x = np.linspace(634.33325195 , 648.24462891 , 100)
    y = result.eval(x=x)
    components = result.eval_components(x=x)

    gauss_y = []

    for i in range(4):
        prefix = f"gauss{i}_"
        params = result.params
        amplitude = params[prefix + "amp"].value
        center = params[prefix + "mu"].value
        sigma = params[prefix + "sigma"].value
        gauss_y.append(amplitude * np.exp(-0.5 * ((xEnergy - center) / sigma) ** 2))

    gauss_y = np.array(gauss_y)

    return gaussPeakEnergy , gaussPeakCounts , tXVals , tYVals , amp_240 , amp_239 , amp_double , amp_middle , fwhm240 , fwhm239 , x , y , components , gauss_y


def main(pcf_file: str , loud = 0):
    
    '''
    Inputs: String directing funtion where to pull spectra from

    Returns:
    
            filteredChannels = array of channels for energies from 600-700keV
            filteredEnergy = array of energy bins from 600-700keV 
            filteredCPS = array of counts per second
            filteredCounts = array of counts
            uncert = array of square root of counts (uncertainty in each count)
            
    Below is an example of opening a .PCF file which contains 350 spectra,
    finding a single WGPu spectrum, converting the counts to CPS, and printing
    CPS in each bin/channel

    ********
    WARNING! Because of a hiccup in my simulations on my other project, there
    are 4097 bins in each spectrum when you should only use 4096. For context,
    this happened because I needed to match my GADRAS-DRF and MCNP simulations.

    You MUST make sure you remove the last channel whenever you grab counts
    from this dataset!

    Example:

    >>> counts_per_bin = [0, 1, ..., 20, 3]
    >>> counts_per_bin_except_last = counts_per_bin[:-1]
    >>> counts_per bin_except_last
    >>>
    >>> [0, 1, ..., 20]
    '''

    ### Define a few constants (just an example, choose what you want/need)
    isWGPu_threshold = 0.07
    deadtime_frac_threshold = 0.10


    spectra = load_spectra(pcf_file)

    ### Find the first WGPu spectrum with acceptable dead time
    for i in range(spectra.numMeasurements()):

        spectrum = spectra.measurement(i)        # Get single measurement i.e., spectrum
        info = parse_title(spectrum.title())     # Get info from the title
        livetime = spectrum.liveTime()           # Get live time
        realtime = spectrum.realTime()           # Get real time
        deadtime_frac = (1-livetime/realtime)    # E.g., if live 10 secs but real 100 secs, deadtime frac = 90%

        # WGPu found with low enough dead time
        if info["PuRatio"] <= isWGPu_threshold and deadtime_frac <= deadtime_frac_threshold:

            energy = np.array(spectrum.channelEnergies())#[:-1]
            energy = energy[1:]
            counts = spectrum.gammaCounts()#[:-1] # Remove last bin for reasons above!
            counts = np.array(counts)#[:-1]       # Convert to np.array for quick array manipulation
            cps = counts/livetime                # Convert to counts per second
            channels = np.arange(1 , len(counts) + 1) # Number of Channels

            maskedEnergy = []

            maskedCounts = []
            
            filteredChannels = [] # Channels for 600-700 keV
            
            filteredEnergy = [] # Energy bins for 600-700 keV
            
            filteredCPS = [] # Counts per second at each bin from 600-700 keV

            filteredCounts = [] # Counts at each bin from 600-700 keV

            uncert = [] # Sqrt of counts (uncertainty in counts)
            
            for i in range(len(energy)):
                
                if 634.33325195 <= energy[i] < 648.24462891:
                    
                    filteredEnergy.append(energy[i])

                    filteredEnergy.append(energy[i] + (energy[i+1]-energy[i])/4)

                    filteredEnergy.append(energy[i] + (energy[i+1]-energy[i])/2)

                    filteredEnergy.append(energy[i] + 3*(energy[i+1]-energy[i])/4)
            
                    filteredCPS.append(cps[i])

                    filteredCounts.append(counts[i]/4)

                    filteredCounts.append((counts[i] + (counts[i+1]-counts[i])/4)/4)

                    filteredCounts.append((counts[i] + (counts[i+1]-counts[i])/2)/4)

                    filteredCounts.append((counts[i] + 3*(counts[i+1]-counts[i])/4)/4)

                    filteredChannels.append(channels[i])

                    maskedEnergy.append(energy[i])

                    maskedCounts.append(counts[i])

            for i in filteredCounts:
                if i == 0:
                        
                    uncert.append(1.0)
                        
                else:
                        
                    uncert.append(np.sqrt(i))

                    
            filteredEnergy = np.array(filteredEnergy)
            
            filteredCPS = np.array(filteredCPS)

            filteredCounts=np.array(filteredCounts)

            filteredChannels = np.array(filteredChannels)

            uncert = np.array(uncert)

            ratio, mass, shield, distance, age , shThic = (
                info['PuRatio'], 
                info['Pu_mass'], 
                info['shd_mat'], 
                info['det_dist'],
                info['age'],
                info['shdor']
                ) #This is turning information from parse_title into useful variables

            EPu240 = 642.23 #keV
            
            EPu239 = 645.94 #keV

            cluster1 = 637.7 #keV

            cluster2 = 637.8 #keV

            cluster3 = 639.99 #keV
            
            EPu239LB = 658.86 #keV
            
                
            '''    ^^^
            According to Brookhaven nuclear data library: https://www.nndc.bnl.gov/nudat3/indx_dec.jsp
            '''
            
            graphVars = multGaussSet(filteredEnergy , filteredCounts , uncert)

            amp240 , amp239 , ampDouble , ampMiddle , fwhm240 , fwhm239 , gaussX , gaussY , gaussModel , individualGauss = (graphVars[4] , graphVars[5] , graphVars[6] ,
                                                            graphVars[7] , graphVars[8] , graphVars[9] , graphVars[10] , graphVars[11] , graphVars[12] , graphVars[13])
                                                                          
            
            break                                # End loop
            
    if loud:

        num_ticks = 10 # Increase for more tick marks

        x_min , x_max = min(filteredEnergy) , max(filteredEnergy)
            
        xticks = np.linspace(x_min, x_max, num_ticks)  # Generate evenly spaced x-ticks
        
        plt.figure(figsize=(10, 5))
        plt.xticks(xticks)  # Apply custom x-ticks
        plt.grid(True)
        plt.yscale('log')
        plt.title(f'{age} Year Aged, {mass}g Sample of {100 - 100 * ratio:.2f}% (atomic) Pu239 with {shThic}cm of {shield} Shielding Taken {distance}cm From Source')
        plt.xlabel('Energy (keV)')
        plt.ylabel('Counts/Second')
        #plt.ylim(0, 10000) # Only needed when plotting the individual Gaussian's becuase they go super negative
        plt.step(maskedEnergy , maskedCounts , color = 'grey' , label = 'Original Data')
        plt.step(filteredEnergy , filteredCounts , color = 'black' , label = 'Interpolated Data')

        '''
        # This should be plotting the 4 individually fitted gaussians, it looks bad though
        for i in range(4):  # assuming 4 components: g0_, g1_, g2_, g3_ 
            y_i = gaussModel[f"gauss{i}_"]  # note the trailing underscore!
            plt.plot(gaussX, y_i, label=f'Gaussian {i}')
        '''
        
        #plt.plot(gaussX , gaussY , color = 'red' , label = 'Overall Gaussian Fit') # Overall Gaussian fit
        '''
        plt.plot(filteredEnergy , individualGauss[0] , label = 'Gauss Fit 1')
        plt.plot(filteredEnergy , individualGauss[1] , label = 'Gauss Fit 2')
        plt.plot(filteredEnergy , individualGauss[2] , label = 'Gauss Fit 3')
        plt.plot(filteredEnergy , individualGauss[3] , label = 'Gauss Fit 4')
        '''
        plt.axvline(x=EPu240, ymin=0, ymax=1 , color = 'orange' , label = 'Peaks of Interest')
        plt.axvline(x=EPu239, ymin=0, ymax=1 , color = 'orange')
        plt.axvline(x=cluster1, ymin=0, ymax=1, color = 'orange')
        plt.axvline(x=cluster2, ymin=0, ymax=1, color = 'orange')
        plt.axvline(x=cluster3, ymin=0, ymax=1, color = 'orange')
        #plt.plot(graphVars[0] , graphVars[1] , marker='x', linestyle='none' , color = 'tab:blue')
        #plt.plot(graphVars[2] , graphVars[3] , marker = 'o' , linestyle = 'none' , color = 'tab:blue' ,
        #         label = 'Range of Interest for De-Convolution') #O markers on troughs around the triple gaussians
        plt.legend()
        plt.show()

        calcRatio = ratioCalc(amp239 , amp240)

        calcRatioAllPeaks = ratioCalcAllPeaks(amp239 , amp240 , ampDouble , ampMiddle)

        error = np.abs((1-ratio)-calcRatio)/(1-ratio) * 100

        print('Sum of original counts:' , sum(maskedCounts))

        print('Sum of interpolated counts:' , sum(filteredCounts))

        print('Pu239 Atomic Percent from Calculation:' , calcRatio*100)
        print('Actual Pu239 Atomic Percent:' , (1-ratio)*100)
        print('Error:' , error , '%')
        
        
        if calcRatio >= 0.93:
            print('Algorithm Produces Green Light')
        else:
            print('Algorithm Produces Red Light')
        
    return filteredChannels , filteredEnergy , filteredCPS , filteredCounts , uncert , ratio , mass , shield , distance , age , shThic


file1 = "Box/2025 Sr Design - Info Barriers/Synthetic Spectra/Pu_Bare_Det60cm_HPGe_outps/Pu_Bare_Det60cm_HPGe_CPS_tally18.pcf"

file2 = "Box/2025 Sr Design - Info Barriers/Synthetic Spectra/Pu_Steel7.5cm_Det60cm_HPGe_outps/Pu_Steel7.5cm_Det60cm_HPGe_CPS_tally18.pcf"

file3 = "Box/2025 Sr Design - Info Barriers/Synthetic Spectra/Pu_Lead0.7cm_Det60cm_HPGe_outps/Pu_Lead0.7cm_Det60cm_HPGe_CPS_tally18.pcf"

file4 = "Box/2025 Sr Design - Info Barriers/Synthetic Spectra/Pu_HDPE4.0cm_Det100cm_HPGe_outps/Pu_HDPE4.0cm_Det100cm_HPGe_CPS_tally18.pcf"

file5 = "Box/2025 Sr Design - Info Barriers/Synthetic Spectra/Pu_Bare_Det60cm_HPGe_outps/Pu_Bare_Det60cm_HPGe_CPS_tally118.pcf"

CZTFile = "Box/2025 Sr Design - Info Barriers/CZT Outputs/Test Source. Cs137 1cm.spe"



if __name__ == "__main__":

    main(file1 , 1)


    
    main(file2, 1)

    main(file3, 1)

    main(file4, 1)

    main(file5, 1)

'''

    main(CZTFile, 1)

    
'''
